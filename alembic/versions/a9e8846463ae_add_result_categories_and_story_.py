"""Add result categories and story displacements for new hierarchy

Revision ID: a9e8846463ae
Revises: c08260852c0f
Create Date: 2025-10-23 21:37:19.409655

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'a9e8846463ae'
down_revision: Union[str, Sequence[str], None] = 'c08260852c0f'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema with data backfill for existing records."""
    # ### commands auto generated by Alembic - please adjust! ###

    # Step 1: Create new tables
    op.create_table('result_categories',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('result_set_id', sa.Integer(), nullable=False),
    sa.Column('category_name', sa.String(length=50), nullable=False),
    sa.Column('category_type', sa.String(length=50), nullable=False),
    sa.ForeignKeyConstraint(['result_set_id'], ['result_sets.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_resultset_category', 'result_categories', ['result_set_id', 'category_name', 'category_type'], unique=True)
    op.create_table('story_displacements',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('story_id', sa.Integer(), nullable=False),
    sa.Column('load_case_id', sa.Integer(), nullable=False),
    sa.Column('result_category_id', sa.Integer(), nullable=True),
    sa.Column('direction', sa.String(length=10), nullable=False),
    sa.Column('displacement', sa.Float(), nullable=False),
    sa.Column('max_displacement', sa.Float(), nullable=True),
    sa.Column('min_displacement', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['load_case_id'], ['load_cases.id'], ),
    sa.ForeignKeyConstraint(['result_category_id'], ['result_categories.id'], ),
    sa.ForeignKeyConstraint(['story_id'], ['stories.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_disp_category', 'story_displacements', ['result_category_id'], unique=False)
    op.create_index('ix_disp_story_case', 'story_displacements', ['story_id', 'load_case_id', 'direction'], unique=False)

    # Step 2: Add columns to existing tables using batch mode for SQLite
    with op.batch_alter_table('story_accelerations', schema=None) as batch_op:
        batch_op.add_column(sa.Column('result_category_id', sa.Integer(), nullable=True))
        batch_op.create_index('ix_accel_category', ['result_category_id'], unique=False)
        batch_op.create_foreign_key('fk_accel_category', 'result_categories', ['result_category_id'], ['id'])

    with op.batch_alter_table('story_drifts', schema=None) as batch_op:
        batch_op.add_column(sa.Column('result_category_id', sa.Integer(), nullable=True))
        batch_op.create_index('ix_drift_category', ['result_category_id'], unique=False)
        batch_op.create_foreign_key('fk_drift_category', 'result_categories', ['result_category_id'], ['id'])

    with op.batch_alter_table('story_forces', schema=None) as batch_op:
        batch_op.add_column(sa.Column('result_category_id', sa.Integer(), nullable=True))
        batch_op.create_index('ix_force_category', ['result_category_id'], unique=False)
        batch_op.create_foreign_key('fk_force_category', 'result_categories', ['result_category_id'], ['id'])

    # Step 3: Backfill data for existing records
    # Get database connection for data operations
    connection = op.get_bind()

    # Check if there are any existing projects with results
    result = connection.execute(sa.text("SELECT COUNT(*) as cnt FROM story_drifts"))
    row = result.fetchone()
    has_existing_data = row is not None and row[0] > 0

    if has_existing_data:
        # Create default result sets for projects that have results but no result set
        connection.execute(sa.text("""
            INSERT INTO result_sets (project_id, name, description, created_at)
            SELECT DISTINCT sd.project_id, 'Legacy', 'Auto-migrated results from previous schema', datetime('now')
            FROM (
                SELECT DISTINCT p.id as project_id
                FROM projects p
                LEFT JOIN result_sets rs ON rs.project_id = p.id
                WHERE rs.id IS NULL
                AND EXISTS (
                    SELECT 1 FROM story_drifts sd2
                    JOIN stories s ON s.id = sd2.story_id
                    WHERE s.project_id = p.id
                )
            ) sd
        """))

        # Create default category (Envelopes â†’ Global) for each result set
        connection.execute(sa.text("""
            INSERT INTO result_categories (result_set_id, category_name, category_type)
            SELECT id, 'Envelopes', 'Global'
            FROM result_sets
            WHERE NOT EXISTS (
                SELECT 1 FROM result_categories rc
                WHERE rc.result_set_id = result_sets.id
            )
        """))

        # Backfill result_category_id for story_drifts
        connection.execute(sa.text("""
            UPDATE story_drifts
            SET result_category_id = (
                SELECT rc.id
                FROM result_categories rc
                JOIN result_sets rs ON rs.id = rc.result_set_id
                JOIN stories s ON s.project_id = rs.project_id
                WHERE s.id = story_drifts.story_id
                  AND rc.category_name = 'Envelopes'
                  AND rc.category_type = 'Global'
                LIMIT 1
            )
            WHERE result_category_id IS NULL
        """))

        # Backfill result_category_id for story_accelerations
        connection.execute(sa.text("""
            UPDATE story_accelerations
            SET result_category_id = (
                SELECT rc.id
                FROM result_categories rc
                JOIN result_sets rs ON rs.id = rc.result_set_id
                JOIN stories s ON s.project_id = rs.project_id
                WHERE s.id = story_accelerations.story_id
                  AND rc.category_name = 'Envelopes'
                  AND rc.category_type = 'Global'
                LIMIT 1
            )
            WHERE result_category_id IS NULL
        """))

        # Backfill result_category_id for story_forces
        connection.execute(sa.text("""
            UPDATE story_forces
            SET result_category_id = (
                SELECT rc.id
                FROM result_categories rc
                JOIN result_sets rs ON rs.id = rc.result_set_id
                JOIN stories s ON s.project_id = rs.project_id
                WHERE s.id = story_forces.story_id
                  AND rc.category_name = 'Envelopes'
                  AND rc.category_type = 'Global'
                LIMIT 1
            )
            WHERE result_category_id IS NULL
        """))

    # Step 4: Drop old column from result_sets using batch mode
    with op.batch_alter_table('result_sets', schema=None) as batch_op:
        batch_op.drop_column('result_category')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###

    # Drop result_category_id from result tables using batch mode
    with op.batch_alter_table('story_forces', schema=None) as batch_op:
        batch_op.drop_constraint('fk_force_category', type_='foreignkey')
        batch_op.drop_index('ix_force_category')
        batch_op.drop_column('result_category_id')

    with op.batch_alter_table('story_drifts', schema=None) as batch_op:
        batch_op.drop_constraint('fk_drift_category', type_='foreignkey')
        batch_op.drop_index('ix_drift_category')
        batch_op.drop_column('result_category_id')

    with op.batch_alter_table('story_accelerations', schema=None) as batch_op:
        batch_op.drop_constraint('fk_accel_category', type_='foreignkey')
        batch_op.drop_index('ix_accel_category')
        batch_op.drop_column('result_category_id')

    # Add back old column to result_sets
    with op.batch_alter_table('result_sets', schema=None) as batch_op:
        batch_op.add_column(sa.Column('result_category', sa.VARCHAR(length=50), nullable=True))

    # Drop new tables
    op.drop_index('ix_disp_story_case', table_name='story_displacements')
    op.drop_index('ix_disp_category', table_name='story_displacements')
    op.drop_table('story_displacements')
    op.drop_index('ix_resultset_category', table_name='result_categories')
    op.drop_table('result_categories')
    # ### end Alembic commands ###
